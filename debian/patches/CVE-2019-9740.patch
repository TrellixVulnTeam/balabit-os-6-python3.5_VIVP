From afe3a4975cf93c97e5d6eb8800e48f368011d37a Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Miro=20Hron=C4=8Dok?= <miro@hroncok.cz>
Date: Sun, 14 Jul 2019 11:07:11 +0200
Subject: [PATCH] bpo-30458: Disallow control chars in http URLs. (GH-12755)
 (#13207)
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

Disallow control chars in http URLs in urllib.urlopen.  This addresses a potential security problem for applications that do not sanity check their URLs where http request headers could be injected.

Disable https related urllib tests on a build without ssl (GH-13032)
These tests require an SSL enabled build. Skip these tests when python is built without SSL to fix test failures.

Use http.client.InvalidURL instead of ValueError as the new error case's exception. (GH-13044)

Co-Authored-By: Miro Hronƒçok <miro@hroncok.cz>
---
 Lib/http/client.py                            | 16 ++++++
 Lib/test/test_urllib.py                       | 55 +++++++++++++++++++
 Lib/test/test_xmlrpc.py                       |  8 ++-
 .../2019-04-10-08-53-30.bpo-30458.51E-DA.rst  |  1 +
 4 files changed, 79 insertions(+), 1 deletion(-)
 create mode 100644 Misc/NEWS.d/next/Security/2019-04-10-08-53-30.bpo-30458.51E-DA.rst

Index: python3.5-3.5.2/Lib/http/client.py
===================================================================
--- python3.5-3.5.2.orig/Lib/http/client.py	2019-08-20 13:27:29.019412583 -0400
+++ python3.5-3.5.2/Lib/http/client.py	2019-08-20 13:27:29.015412570 -0400
@@ -141,6 +141,16 @@ _MAXHEADERS = 100
 _is_legal_header_name = re.compile(rb'[^:\s][^:\r\n]*').fullmatch
 _is_illegal_header_value = re.compile(rb'\n(?![ \t])|\r(?![ \t\n])').search
 
+# These characters are not allowed within HTTP URL paths.
+#  See https://tools.ietf.org/html/rfc3986#section-3.3 and the
+#  https://tools.ietf.org/html/rfc3986#appendix-A pchar definition.
+# Prevents CVE-2019-9740.  Includes control characters such as \r\n.
+# We don't restrict chars above \x7f as putrequest() limits us to ASCII.
+_contains_disallowed_url_pchar_re = re.compile('[\x00-\x20\x7f]')
+# Arguably only these _should_ allowed:
+#  _is_allowed_url_pchars_re = re.compile(r"^[/!$&'()*+,;=:@%a-zA-Z0-9._~-]+$")
+# We are more lenient for assumed real world compatibility purposes.
+
 # We always set the Content-Length header for these methods because some
 # servers will otherwise respond with a 411
 _METHODS_EXPECTING_BODY = {'PATCH', 'POST', 'PUT'}
@@ -977,6 +987,12 @@ class HTTPConnection:
         self._method = method
         if not url:
             url = '/'
+        # Prevent CVE-2019-9740.
+        match = _contains_disallowed_url_pchar_re.search(url)
+        if match:
+            raise InvalidURL("URL can't contain control characters. {!r} "
+                             "(found at least {!r})".format(url,
+                                                            match.group()))
         request = '%s %s %s' % (method, url, self._http_vsn_str)
 
         # Non-ASCII characters should have been eliminated earlier
Index: python3.5-3.5.2/Lib/test/test_urllib.py
===================================================================
--- python3.5-3.5.2.orig/Lib/test/test_urllib.py	2019-08-20 13:27:29.019412583 -0400
+++ python3.5-3.5.2/Lib/test/test_urllib.py	2019-08-20 13:27:29.015412570 -0400
@@ -326,6 +326,61 @@ class urlopen_HttpTests(unittest.TestCas
         finally:
             self.unfakehttp()
 
+    @unittest.skipUnless(ssl, "ssl module required")
+    def test_url_with_control_char_rejected(self):
+        for char_no in list(range(0, 0x21)) + [0x7f]:
+            char = chr(char_no)
+            schemeless_url = "//localhost:7777/test{}/".format(char)
+            self.fakehttp(b"HTTP/1.1 200 OK\r\n\r\nHello.")
+            try:
+                # We explicitly test urllib.request.urlopen() instead of the top
+                # level 'def urlopen()' function defined in this... (quite ugly)
+                # test suite.  They use different url opening codepaths.  Plain
+                # urlopen uses FancyURLOpener which goes via a codepath that
+                # calls urllib.parse.quote() on the URL which makes all of the
+                # above attempts at injection within the url _path_ safe.
+                escaped_char_repr = repr(char).replace('\\', r'\\')
+                InvalidURL = http.client.InvalidURL
+                with self.assertRaisesRegex(
+                    InvalidURL,
+                    "contain control.*{}".format(escaped_char_repr)):
+                    urllib.request.urlopen("http:{}".format(schemeless_url))
+                with self.assertRaisesRegex(
+                    InvalidURL,
+                    "contain control.*{}".format(escaped_char_repr)):
+                    urllib.request.urlopen("https:{}".format(schemeless_url))
+                # This code path quotes the URL so there is no injection.
+                resp = urlopen("http:{}".format(schemeless_url))
+                self.assertNotIn(char, resp.geturl())
+            finally:
+                self.unfakehttp()
+
+    @unittest.skipUnless(ssl, "ssl module required")
+    def test_url_with_newline_header_injection_rejected(self):
+        self.fakehttp(b"HTTP/1.1 200 OK\r\n\r\nHello.")
+        host = "localhost:7777?a=1 HTTP/1.1\r\nX-injected: header\r\nTEST: 123"
+        schemeless_url = "//" + host + ":8080/test/?test=a"
+        try:
+            # We explicitly test urllib.request.urlopen() instead of the top
+            # level 'def urlopen()' function defined in this... (quite ugly)
+            # test suite.  They use different url opening codepaths.  Plain
+            # urlopen uses FancyURLOpener which goes via a codepath that
+            # calls urllib.parse.quote() on the URL which makes all of the
+            # above attempts at injection within the url _path_ safe.
+            InvalidURL = http.client.InvalidURL
+            with self.assertRaisesRegex(
+                InvalidURL, r"contain control.*\\r.*(found at least . .)"):
+                urllib.request.urlopen("http:{}".format(schemeless_url))
+            with self.assertRaisesRegex(InvalidURL, r"contain control.*\\n"):
+                urllib.request.urlopen("https:{}".format(schemeless_url))
+            # This code path quotes the URL so there is no injection.
+            resp = urlopen("http:{}".format(schemeless_url))
+            self.assertNotIn(' ', resp.geturl())
+            self.assertNotIn('\r', resp.geturl())
+            self.assertNotIn('\n', resp.geturl())
+        finally:
+            self.unfakehttp()
+
     def test_read_0_9(self):
         # "0.9" response accepted (but not "simple responses" without
         # a status line)
Index: python3.5-3.5.2/Lib/test/test_xmlrpc.py
===================================================================
--- python3.5-3.5.2.orig/Lib/test/test_xmlrpc.py	2019-08-20 13:27:29.019412583 -0400
+++ python3.5-3.5.2/Lib/test/test_xmlrpc.py	2019-08-20 13:27:29.019412583 -0400
@@ -808,7 +808,13 @@ class SimpleServerTestCase(BaseServerTes
     def test_partial_post(self):
         # Check that a partial POST doesn't make the server loop: issue #14001.
         conn = http.client.HTTPConnection(ADDR, PORT)
-        conn.request('POST', '/RPC2 HTTP/1.0\r\nContent-Length: 100\r\n\r\nbye')
+        conn.send('POST /RPC2 HTTP/1.0\r\n'
+                  'Content-Length: 100\r\n\r\n'
+                  'bye HTTP/1.1\r\n'
+                  'Host: {}:{}\r\n'
+                  'Accept-Encoding: identity\r\n'
+                  'Content-Length: 0\r\n\r\n'
+                  .format(ADDR, PORT).encode('ascii'))
         conn.close()
 
     def test_context_manager(self):
